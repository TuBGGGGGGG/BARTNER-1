{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pybuilddir.txt\n",
      "pybuilddir.txt\n",
      "/usr/share/zoneinfo/UTC\n",
      "/usr/lib/ssl/certs/ca-certificates.crt\n",
      "[SET SEED]:  4373\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from data.pipe import BartNERPipe\n",
    "from model.bart import BartSeq2SeqModel\n",
    "import fitlog\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from fastNLP import Trainer\n",
    "from model.metrics import Seq2SeqSpanMetric\n",
    "from model.losses import Seq2SeqLoss\n",
    "from torch import optim\n",
    "from fastNLP import BucketSampler, GradientClipCallback, cache_results\n",
    "\n",
    "from model.callbacks import WarmupCallback\n",
    "from fastNLP.core.sampler import SortedSampler\n",
    "from model.generater import SequenceGeneratorModel\n",
    "from fastNLP.core.sampler import  ConstTokenNumSampler\n",
    "from model.callbacks import FitlogCallback\n",
    "\n",
    "fitlog.debug()\n",
    "fitlog.set_log_dir('logs')\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset_name', default='en_ace04', type=str)\n",
    "\n",
    "def set_seed(seed=1996):\n",
    "    print(\"[SET SEED]: \",seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "args= parser.parse_args([])\n",
    "dataset_name = args.dataset_name\n",
    "args.length_penalty = 1\n",
    "args.save_model = 1\n",
    "\n",
    "# word: 生成word的start; bpe: 生成所有的bpe; span: 每一段按照start end生成; span_bpe: 每一段都是start的所有bpe，end的所有bpe\n",
    "args.target_type = 'word'\n",
    "args.bart_name = '/disk1/wxl/Desktop/DeepKE/example/ner/huggingface/bart-large'\n",
    "args.schedule = 'linear'\n",
    "args.decoder_type = 'avg_feature'\n",
    "args.n_epochs = 30\n",
    "args.num_beams = 1\n",
    "args.batch_size = 16\n",
    "args.use_encoder_mlp = 1\n",
    "args.lr = 1e-5\n",
    "args.warmup_ratio = 0.01\n",
    "eval_start_epoch = 1\n",
    "\n",
    "# the following hyper-parameters are for target_type=word\n",
    "if dataset_name == 'conll2003':  # three runs get 93.18/93.18/93.36 F1\n",
    "    max_len, max_len_a = 10, 0.6\n",
    "elif dataset_name == 'en-ontonotes':  # three runs get 90.46/90.4/90/52 F1\n",
    "    max_len, max_len_a = 10, 0.8\n",
    "elif dataset_name == 'CADEC':\n",
    "    max_len, max_len_a = 10, 1.6\n",
    "    args.num_beams = 4\n",
    "    args.lr = 2e-5\n",
    "    args.n_epochs = 30\n",
    "    eval_start_epoch=10\n",
    "elif dataset_name == 'Share_2013':\n",
    "    max_len, max_len_a = 10, 0.6\n",
    "    args.use_encoder_mlp = 0\n",
    "    args.num_beams = 4\n",
    "    args.lr = 2e-5\n",
    "    eval_start_epoch = 5\n",
    "elif dataset_name == 'Share_2014':\n",
    "    max_len, max_len_a = 10, 0.6\n",
    "    args.num_beams = 4\n",
    "    eval_start_epoch = 5\n",
    "    args.n_epochs = 30\n",
    "elif dataset_name == 'genia':  # three runs: 79.29/79.13/78.75\n",
    "    max_len, max_len_a = 10, 0.5\n",
    "    args.target_type = 'span'\n",
    "    args.lr = 2e-5\n",
    "    args.warmup_ratio = 0.01\n",
    "elif dataset_name == 'en_ace04':  # four runs: 86.84/86.33/87/87.17\n",
    "    max_len, max_len_a = 50, 1.1\n",
    "    args.n_epochs = 55\n",
    "    args.batch_size = 48\n",
    "    args.lr = 4e-5\n",
    "    seed = 4373\n",
    "elif dataset_name == 'en_ace05':  # three runs: 85.39/84.54/84.75\n",
    "    max_len, max_len_a = 50, 0.7\n",
    "    args.lr = 3e-5\n",
    "    args.batch_size = 12\n",
    "    args.num_beams = 4\n",
    "    args.warmup_ratio = 0.1\n",
    "\n",
    "set_seed(seed)\n",
    "# with open(\"/disk1/wxl/Desktop/DeepKE/example/baseline/BARTNER/loss_log/D.json\",\"r\") as f:\n",
    "#     b=f.readlines()\n",
    "# with open(\"/disk1/wxl/Desktop/DeepKE/example/baseline/BARTNER/loss_log/E.json\",\"r\") as f:\n",
    "#     c=f.readlines()\n",
    "# for x,y in zip(b,c):\n",
    "#     assert x==y,print(x,y)\n",
    "# exit()\n",
    "\n",
    "save_model = args.save_model\n",
    "del args.save_model\n",
    "lr = args.lr\n",
    "n_epochs = args.n_epochs\n",
    "batch_size = args.batch_size\n",
    "num_beams = args.num_beams\n",
    "\n",
    "length_penalty = args.length_penalty\n",
    "if isinstance(args.decoder_type, str) and args.decoder_type.lower() == 'none':\n",
    "    args.decoder_type = None\n",
    "decoder_type = args.decoder_type\n",
    "target_type = args.target_type\n",
    "bart_name = args.bart_name\n",
    "schedule = args.schedule\n",
    "use_encoder_mlp = args.use_encoder_mlp\n",
    "\n",
    "fitlog.add_hyper(args)\n",
    "\n",
    "#######hyper\n",
    "#######hyper\n",
    "\n",
    "demo = False\n",
    "if demo:\n",
    "    cache_fn = f\"caches/data_{bart_name}_{dataset_name}_{target_type}_demo.pt\"\n",
    "else:\n",
    "    cache_fn = f\"caches/data_{bart_name}_{dataset_name}_{target_type}.pt\"\n",
    "\n",
    "@cache_results(cache_fn, _refresh=False)\n",
    "def get_data():\n",
    "    pipe = BartNERPipe(tokenizer=bart_name, dataset_name=dataset_name, target_type=target_type)\n",
    "    if dataset_name == 'conll2003':\n",
    "        paths = {'test': \"./data/conll2003/test.txt\",\n",
    "                 'train': \"./data/conll2003/train.txt\",\n",
    "                 'dev': \"./data/conll2003/dev.txt\"}\n",
    "        data_bundle = pipe.process_from_file(paths, demo=demo)\n",
    "    elif dataset_name == 'en-ontonotes':\n",
    "        paths = './data/en-ontonotes/english'\n",
    "        data_bundle = pipe.process_from_file(paths)\n",
    "    else:\n",
    "        data_bundle = pipe.process_from_file(f'./data/{dataset_name}', demo=demo)\n",
    "    return pipe, data_bundle, pipe.tokenizer, pipe.mapping2id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read cache from caches/data_/disk1/wxl/Desktop/DeepKE/example/ner/huggingface/bart-large_en_ace04_word.pt.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6195"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe, data_bundle, tokenizer, mapping2id = get_data()\n",
    "ds = data_bundle.get_dataset(\"train\")\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastNLP import DataSet,DataSetIter\n",
    "from fastNLP import SequentialSampler\n",
    "# ds_ = DataSet()\n",
    "# ds_ =ds.load(\"/disk1/wxl/Desktop/DeepKE/example/baseline/BARTNER/caches/ds_final_11_18.pt\")\n",
    "# ds_ = data_bundle.get_dataset('test')\n",
    "sampler = SequentialSampler()\n",
    "batch = DataSetIter(batch_size=48, dataset=ds, sampler=sampler)\n",
    "# model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceGeneratorModel(\n",
       "  (seq2seq_model): BartSeq2SeqModel(\n",
       "    (encoder): FBartEncoder(\n",
       "      (bart_encoder): BartEncoder(\n",
       "        (embed_tokens): Embedding(50277, 1024)\n",
       "        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "        (layers): ModuleList(\n",
       "          (0-11): 12 x EncoderLayer(\n",
       "            (self_attn): Attention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder): CaGFBartDecoder(\n",
       "      (decoder): BartDecoder(\n",
       "        (embed_tokens): Embedding(50277, 1024)\n",
       "        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "        (layers): ModuleList(\n",
       "          (0-11): 12 x DecoderLayer(\n",
       "            (self_attn): Attention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): Attention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (encoder_mlp): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (1): Dropout(p=0.3, inplace=False)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout_layer): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=torch.load(\"/disk1/wxl/Desktop/DeepKE/example/baseline/BARTNER/save_models/en_ace04_3257/best_SequenceGeneratorModel_f_2024-11-18-22-16-54-082796\").to('cuda')\n",
    "model2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2806, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2363, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3205, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2595, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3844, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4129, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3870, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3671, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2767, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4033, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3459, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2539, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2820, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4573, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3390, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3202, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2460, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3152, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3763, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3564, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3144, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3458, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2733, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3143, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2336, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3491, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3395, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2957, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2648, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2798, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3111, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3734, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3223, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3410, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3200, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3078, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3139, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3684, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3213, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2961, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4392, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2711, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3896, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3320, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3402, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3072, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4216, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2832, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3152, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3517, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3160, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3460, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2915, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2570, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2576, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3785, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2894, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3300, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3528, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4272, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1620, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3301, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3480, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3504, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3243, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2498, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1909, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2978, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2022, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3034, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2793, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2350, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2794, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2289, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3049, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1878, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2577, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2177, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3039, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2409, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3021, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3024, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1936, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4212, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3402, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3267, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2464, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2401, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2452, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3763, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2189, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4174, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4096, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2588, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2864, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2815, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4019, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3337, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3228, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3843, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2955, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2284, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2336, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3217, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4012, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3189, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3301, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2840, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2829, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2581, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3236, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3591, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2509, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2837, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4315, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2421, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2658, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4355, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3158, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3218, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3748, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3401, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3513, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3987, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2979, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "losser = Seq2SeqLoss(max_type_id=9)\n",
    "for i in batch:\n",
    "    torch.set_printoptions(threshold=float('Inf'), linewidth=120)\n",
    "    pred = model2(src_tokens = i[0][\"src_tokens\"].to('cuda'), tgt_tokens = i[0][\"tgt_tokens\"].to('cuda'), src_seq_len=i[0][\"src_seq_len\"].to('cuda'), tgt_seq_len = i[0][\"tgt_seq_len\"].to('cuda'), first = i[0][\"first\"].to('cuda'))[\"pred\"]\n",
    "    \n",
    "    try:\n",
    "        x = losser.get_loss(i[0][\"tgt_tokens\"].to('cuda'), i[0][\"tgt_seq_len\"].to('cuda'), pred)\n",
    "    except:\n",
    "        x = losser.get_loss(i[0][\"tgt_tokens\"].to('cuda'), i[0][\"tgt_seq_len\"].to('cuda'), pred)\n",
    "        break\n",
    "    print(x)\n",
    "    x.backward()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1247, 0.1124, 0.8228, 0.2431, 0.8098, 0.4280, 0.2890, 0.8662],\n",
      "        [0.6910, 0.6694, 0.3225, 0.4668, 0.6682, 0.7839, 0.3350, 0.6885],\n",
      "        [0.0898, 0.1108, 0.8681, 0.3213, 0.4025, 0.1291, 0.2293, 0.8221]])\n",
      "tensor([0, 0, 1, 1, 1, 2]) tensor([0, 3, 0, 1, 3, 3])\n",
      "tensor([2, 3, 2]) torch.Size([3, 4]) tensor([False, False, False])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "x=torch.rand(3,8)\n",
    "print(x)\n",
    "eos = x[:,1] >1\n",
    "tag = x[:, 2:4].argmax(dim=-1) + 2\n",
    "mask = x[:,4:]>0.5\n",
    "rows, cols = torch.where(mask)\n",
    "print(rows, cols)\n",
    "word = []\n",
    "max_len = 1\n",
    "eos_element = torch.tensor([1])\n",
    "for r in range(x.size(0)):\n",
    "    if eos[r]:\n",
    "        word.append(eos_element)\n",
    "    else:\n",
    "        add_v = torch.cat((cols[rows == r]+4, tag[r:r+1]))\n",
    "        if len(add_v) == 1:\n",
    "            word.append(eos_element) # 虽然有实体类型，并且不是eos，但是实体内容为空，则按照eos处理\n",
    "        else:\n",
    "            word.append(add_v)\n",
    "        max_len = max(max_len, len(add_v))\n",
    "word = torch.cat([F.pad(i, (0, max_len-len(i)), mode='constant', value=-1).unsqueeze(0) for i in word])\n",
    "print(tag, word.squeeze(-1).shape, eos)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4849,  0.7694, -1.0000, -1.0000, -1.0000],\n",
      "        [ 0.4539,  0.5514,  0.8879, -1.0000, -1.0000],\n",
      "        [ 0.9258,  0.9665,  0.8730,  0.9829, -1.0000],\n",
      "        [ 0.7957,  0.6666,  0.4052,  0.0504,  0.5711]]) tensor([0.4849, 0.7694, 0.4539, 0.5514, 0.8879])\n",
      "torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "x= torch.rand(4,5)\n",
    "x[0][2:]=-1\n",
    "x[1][3:]=-1\n",
    "x[2][4:]=-1\n",
    "result = [row[row != -1] for row in x]\n",
    "print(x,torch.cat([result[0],result[1]],dim=-1))\n",
    "print(x.squeeze(1).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
